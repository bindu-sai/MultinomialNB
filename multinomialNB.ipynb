{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pranjubindu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pranjubindu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('smallTrain.csv',encoding='Latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as much as i love to be hopeful, i reckon the...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I really really like the song Love Story by Ta...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My Sharpie is running DANGERously low on ink</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i want to go to music tonight but i lost my vo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Uh oh, I am sunburned</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S`ok, trying to plot alternatives as we speak...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i`ve been sick for the past few days  and thus...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>is back home now      gonna miss every one</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hes just not that into you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet sentiment\n",
       "0                 I`d have responded, if I were going   neutral\n",
       "1       Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2                           my boss is bullying me...  negative\n",
       "3                      what interview! leave me alone  negative\n",
       "4    Sons of ****, why couldn`t they put them on t...  negative\n",
       "5   http://www.dothebouncy.com/smf - some shameles...   neutral\n",
       "6   2am feedings for the baby are fun when he is a...  positive\n",
       "7                                          Soooo high   neutral\n",
       "8                                         Both of you   neutral\n",
       "9    Journey!? Wow... u just became cooler.  hehe....  positive\n",
       "10   as much as i love to be hopeful, i reckon the...   neutral\n",
       "11  I really really like the song Love Story by Ta...  positive\n",
       "12       My Sharpie is running DANGERously low on ink  negative\n",
       "13  i want to go to music tonight but i lost my vo...  negative\n",
       "14                         test test from the LG enV2   neutral\n",
       "15                              Uh oh, I am sunburned  negative\n",
       "16   S`ok, trying to plot alternatives as we speak...  negative\n",
       "17  i`ve been sick for the past few days  and thus...  negative\n",
       "18         is back home now      gonna miss every one  negative\n",
       "19                         Hes just not that into you   neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet        1\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_text(a):\n",
    "    a=str(a)\n",
    "    text=re.sub('[^a-zA-Z]',' ',a)\n",
    "    text=text.lower()\n",
    "    text=nltk.word_tokenize(text)\n",
    "    text=[wordnet.lemmatize(word) for word in text if word not in stopwords.words('english')]\n",
    "    text=' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>responded going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bos bullying</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interview leave alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>son put release already bought</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            tweet sentiment\n",
       "0                 responded going   neutral\n",
       "1         sooo sad miss san diego  negative\n",
       "2                    bos bullying  negative\n",
       "3           interview leave alone  negative\n",
       "4  son put release already bought  negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']=df['tweet'].apply(change_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(message):\n",
    "    if(message=='positive'):\n",
    "        return(1)\n",
    "    elif(message=='negative'):\n",
    "        return(-1)\n",
    "    else:\n",
    "        return(0)\n",
    "df['label']=df['sentiment'].apply(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cf=CountVectorizer()\n",
    "X1=cf.fit_transform(df['tweet'])\n",
    "#.values.astype('U'))\n",
    "y=df['label']'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X1= vectorizer.fit_transform(df['tweet'])\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv=ShuffleSplit(n_splits=10,test_size=0.2,random_state=42)\n",
    "#cv = StratifiedShuffleSplit(n_splits=5, test_size=0.4, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6196107  0.61870111 0.62033837 0.62543205 0.63034382 0.61160633\n",
      " 0.61797344 0.61797344 0.61197017 0.6248863 ]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(MultinomialNB(),X1,y,cv=cv,scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6198835728579225\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(MultinomialNB(),X1,y,cv=cv,scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X1,y,test_size=0.3,random_state=42)\n",
    "\n",
    "nb=MultinomialNB()\n",
    "\n",
    "nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 922, 1294,  122],\n",
       "       [ 208, 2751,  412],\n",
       "       [  43, 1022, 1471]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.39      0.53      2338\n",
      "           0       0.54      0.82      0.65      3371\n",
      "           1       0.73      0.58      0.65      2536\n",
      "\n",
      "    accuracy                           0.62      8245\n",
      "   macro avg       0.69      0.60      0.61      8245\n",
      "weighted avg       0.67      0.62      0.61      8245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6238932686476653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessToken=\"1272053768067010562-u4eunjqdSTtiE68q2J0x2NceCY4Jwx\"\n",
    "accessTokenSecret=\"8FZbdPVlqW1T5LhL2blrXzJgH9PXcty6wvHW0NFRqiHTR\"\n",
    "consumerKey=\"F0w2fjOVn4EUAH0MIjhA6lbDY\"\n",
    "consumerKeySecret=\"Bz5BJwUxx6GlSA7AtENuoXPAfV16UkMTSBngquicAh9PyEuBAX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth=tweepy.OAuthHandler(consumerKey,consumerKeySecret)\n",
    "auth.set_access_token(accessToken,accessTokenSecret)\n",
    "api=tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text=re.sub('https?://[^\\s]+','URL',text)\n",
    "    text=re.sub('@[^\\s]+','',text)\n",
    "    text=re.sub(r'#','',text)\n",
    "    text=re.sub(r'RT[\\s]','',text)\n",
    "    text=re.sub('\\n',\"\",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many tweets to analyze20\n",
      "Topic:exams\n"
     ]
    }
   ],
   "source": [
    "numOfTweets= int(input('How many tweets to analyze'))\n",
    "searchWord=input(\"Topic:\")\n",
    "date_since=\"2020-03-10\"\n",
    "tweets=tweepy.Cursor(api.search, q=searchWord, lang='en',since=date_since,tweet_mode=\"extended\").items(numOfTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweets\n",
      "0    So my wife has completed her exams.It’s been ...\n",
      "1    Aaditya Thackeray Moves Supreme Court Against...\n",
      "2    Whichever govt is planning to conduct exams D...\n",
      "3    eye exams feel so personal like are we gonna ...\n",
      "4    Basically this. Brilliantly written article b...\n",
      "5   One sem of exam will be determinative of the i...\n",
      "6    Respected  Sir The cases are increasing rando...\n",
      "7     Pls ask d government 2 give lisence 2 d 2000...\n",
      "8    Compartment exam will not held on the epidemi...\n",
      "9    eye exams feel so personal like are we gonna ...\n",
      "10   Omg I have to read this - I was taught rate p...\n",
      "11   Sir,we are suffering from many problems.clear...\n",
      "12   Twenty years ago this week, the Chunin Select...\n",
      "13    🛑Our one year is being wasted in front of ev...\n",
      "14   Yet another victory for Odisha Govt. decided ...\n",
      "15   Respected government officials current scenar...\n",
      "16   Sharing this inspiring story of a 50-year-old...\n",
      "17   Madhwa girl secures 1st rank in 12th Std exam...\n",
      "18   YoutubeIndia bringbackexampurDear  , we are a...\n",
      "19   Respected  Sir The cases are increasing rando...\n"
     ]
    }
   ],
   "source": [
    "df_user_tweets=pd.DataFrame([tweet.full_text for tweet in tweets],columns=['Tweets'])\n",
    "df_user_tweets['Tweets']=df_user_tweets['Tweets'].apply(cleanText)\n",
    "print(df_user_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(message):\n",
    "    if(nb.predict(vectorizer.transform([change_text(message)]))==1):\n",
    "        return 'Positive'\n",
    "    elif(nb.predict(vectorizer.transform([change_text(message)]))==0):\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'Negavite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_tweets['Analysis']=df_user_tweets['Tweets'].apply(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So my wife has completed her exams.It’s been ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaditya Thackeray Moves Supreme Court Against...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whichever govt is planning to conduct exams D...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eye exams feel so personal like are we gonna ...</td>\n",
       "      <td>Negavite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basically this. Brilliantly written article b...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>One sem of exam will be determinative of the i...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Respected  Sir The cases are increasing rando...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pls ask d government 2 give lisence 2 d 2000...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Compartment exam will not held on the epidemi...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>eye exams feel so personal like are we gonna ...</td>\n",
       "      <td>Negavite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Omg I have to read this - I was taught rate p...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sir,we are suffering from many problems.clear...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Twenty years ago this week, the Chunin Select...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>🛑Our one year is being wasted in front of ev...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yet another victory for Odisha Govt. decided ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Respected government officials current scenar...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sharing this inspiring story of a 50-year-old...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Madhwa girl secures 1st rank in 12th Std exam...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>YoutubeIndia bringbackexampurDear  , we are a...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Respected  Sir The cases are increasing rando...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweets  Analysis\n",
       "0    So my wife has completed her exams.It’s been ...   neutral\n",
       "1    Aaditya Thackeray Moves Supreme Court Against...   neutral\n",
       "2    Whichever govt is planning to conduct exams D...   neutral\n",
       "3    eye exams feel so personal like are we gonna ...  Negavite\n",
       "4    Basically this. Brilliantly written article b...   neutral\n",
       "5   One sem of exam will be determinative of the i...   neutral\n",
       "6    Respected  Sir The cases are increasing rando...   neutral\n",
       "7     Pls ask d government 2 give lisence 2 d 2000...   neutral\n",
       "8    Compartment exam will not held on the epidemi...   neutral\n",
       "9    eye exams feel so personal like are we gonna ...  Negavite\n",
       "10   Omg I have to read this - I was taught rate p...   neutral\n",
       "11   Sir,we are suffering from many problems.clear...   neutral\n",
       "12   Twenty years ago this week, the Chunin Select...   neutral\n",
       "13    🛑Our one year is being wasted in front of ev...   neutral\n",
       "14   Yet another victory for Odisha Govt. decided ...   neutral\n",
       "15   Respected government officials current scenar...   neutral\n",
       "16   Sharing this inspiring story of a 50-year-old...   neutral\n",
       "17   Madhwa girl secures 1st rank in 12th Std exam...   neutral\n",
       "18   YoutubeIndia bringbackexampurDear  , we are a...   neutral\n",
       "19   Respected  Sir The cases are increasing rando...   neutral"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_tweets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(vectorizer.transform([change_text(\"it is worst movie\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(vectorizer.transform([change_text(\"carolyn cooper | ugly, poor, ignorant and black!  \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(vectorizer.transform([change_text(\"i am ugly\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(vectorizer.transform([change_text(\"i am super\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(vectorizer.transform([change_text(\"i am alone\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(vectorizer.transform([change_text(\"i am wonderful\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(vectorizer.transform([change_text(\"hi\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(vectorizer.transform([change_text(\"is it pen stand?\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
